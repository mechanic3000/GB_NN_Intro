{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObQVpharT7OESPNhMIWHkp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mechanic3000/GB_NN_Intro/blob/Lesson_04/Lesson_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Практическое задание\n",
        "\n",
        "<ol>\n",
        "    <li>Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
        "    </li>\n",
        "    <li>Описать также в анализе какие необоходимо внести изменения  в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
        "    </li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "F14GXDADivU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNFahkAUijj5",
        "outputId": "54fbedec-3121-4e80-ba4d-e91fabc445bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n",
            "Использование data augmentation в реальном времени\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c41aa95c2f64>:107: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 36s 45ms/step - loss: 1.9939 - accuracy: 0.2695 - val_loss: 1.7090 - val_accuracy: 0.4004\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 1.7393 - accuracy: 0.3674 - val_loss: 1.5614 - val_accuracy: 0.4380\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 36s 45ms/step - loss: 1.6232 - accuracy: 0.4077 - val_loss: 1.4870 - val_accuracy: 0.4698\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.5438 - accuracy: 0.4350 - val_loss: 1.3666 - val_accuracy: 0.5043\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 34s 44ms/step - loss: 1.4850 - accuracy: 0.4630 - val_loss: 1.3350 - val_accuracy: 0.5195\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.4334 - accuracy: 0.4838 - val_loss: 1.2805 - val_accuracy: 0.5469\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 1.3884 - accuracy: 0.5027 - val_loss: 1.2585 - val_accuracy: 0.5515\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.3492 - accuracy: 0.5188 - val_loss: 1.1733 - val_accuracy: 0.5838\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.3125 - accuracy: 0.5334 - val_loss: 1.1578 - val_accuracy: 0.5870\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 36s 45ms/step - loss: 1.2806 - accuracy: 0.5422 - val_loss: 1.1246 - val_accuracy: 0.6023\n",
            "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1246 - accuracy: 0.6023\n",
            "Test loss: 1.124634027481079\n",
            "Test accuracy: 0.6022999882698059\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# установка параметров нейросети\n",
        "# batch_size = 32\n",
        "# batch_size = 16\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "# epochs = 1\n",
        "epochs = 10\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    # datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка исходной модели\n",
        "\n",
        "# Test loss: 1.5661115646362305\n",
        "# Test accuracy: 0.42969998717308044\n",
        "# ###################################\n",
        "\n",
        "# Оценка при изменении:\n",
        "\n",
        "# Кол-во эпох = 3\n",
        "# Test loss: 1.3396382331848145\n",
        "# Test accuracy: 0.5149000287055969\n",
        "\n",
        "# batch = 16\n",
        "# Test loss: 1.1925313472747803\n",
        "# Test accuracy: 0.5727999806404114\n",
        "\n",
        "# значения Droput (0.1, 0.1, 0.15):\n",
        "# Test loss: 1.1160888671875\n",
        "# Test accuracy: 0.6051999926567078\n",
        "\n",
        "# уменьшил количество слоев, убрал один pooling\n",
        "# Test loss: 1.0581334829330444\n",
        "# Test accuracy: 0.6236000061035156\n",
        "\n",
        "\n",
        "\n",
        "# Выводы: \n",
        "# 1\n",
        "# На увеличение оценки вляет увеличение количества эпох, \n",
        "#   уменьшение размера батча,\n",
        "#   сничение количества данных попадающих в Дропаут (для частных случаев),\n",
        "#   снижение количества слоев также сыграло положительную роль в увеличении оценки\n",
        "\n",
        "# 2\n",
        "  # Для работы с MNIST, CIFAR100 и IMAGENET в текущей сети необходимо изменить входные параметры,\n",
        "  # т.к. у этих датасетов изображения разного размера, а также установить количество нейронов в последнем\n",
        "  # слое соответствующее количеству классов в датасете.\n",
        "  # Остальные параметры подбираются в процессе."
      ],
      "metadata": {
        "id": "NQCUV4x7RJj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}